{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PoweredArm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ic4_EVMfHvs1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJMEelAoKzg_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sc = MinMaxScaler(feature_range = (0, 1))\n",
        "\n",
        "rock_dataset = pd.read_csv('/content/0.csv', header=None) # class = 0\n",
        "scissors_dataset = pd.read_csv(\"/content/1.csv\", header=None) # class = 1\n",
        "paper_dataset = pd.read_csv(\"/content/2.csv\", header=None) # class = 2\n",
        "ok_dataset = pd.read_csv(\"/content/3.csv\", header=None) # class = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NP-RN4eHK_LS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "frames = [rock_dataset, scissors_dataset, paper_dataset, ok_dataset]\n",
        "dataset = pd.concat(frames )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PVedfIgLIUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_train = dataset.iloc[np.random.permutation(len(dataset))]\n",
        "dataset_train.reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSK5aQF3LSpx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "for i in range(0, dataset_train.shape[0]):\n",
        "    row = np.array(dataset_train.iloc[i:1+i, 0:64].values)\n",
        "    X_train.append(np.reshape(row, (64, 1)))\n",
        "    y_train.append(np.array(dataset_train.iloc[i:1+i, -1:])[0][0])\n",
        "    \n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS5RCZRcLVxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshape\n",
        "X_train = X_train.reshape(X_train.shape[0]*X_train.shape[1], 1)\n",
        "X_train = sc.fit_transform(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mxngl1CiLXfx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshape after normalization to (-1, 8, 8)\n",
        "X_train = X_train.reshape((-1, 8, 8))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEZRPfGpLZp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# One hot encoding\n",
        "#y_train = np.eye(np.max(y_train.astype(int)) + 1)[y_train.astype(int)]\n",
        "y_train = np.eye(np.max(y_train) + 1)[y_train]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nj8v6cqPpQNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"All Data size X and y\")\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "# Splitting Train/Test\n",
        "X_test = X_train[7700:]\n",
        "y_test = y_train[7700:]\n",
        "print(\"Test Data size X and y\")\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "X_train = X_train[0:7700]\n",
        "y_train = y_train[0:7700]\n",
        "print(\"Train Data size X and y\")\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSzj-p43pVdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating the model\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "classifier = Sequential()\n",
        "\n",
        "classifier.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 8)))\n",
        "classifier.add(Dropout(0.2))\n",
        "\n",
        "classifier.add(LSTM(units = 50))\n",
        "classifier.add(Dropout(0.2))\n",
        "\n",
        "classifier.add(Dense(units = 64))\n",
        "\n",
        "classifier.add(Dense(units = 4, activation=\"softmax\"))\n",
        "\n",
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5qoClospj3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.fit(X_train, y_train, epochs = 20, batch_size = 32, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBZa_bZpH30s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Save\n",
        "classifier.save(\"model_cross_splited_data.h5\")\n",
        "print(\"Saved model to disk\")\n",
        "\n",
        "###############################################\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "# # Load Model\n",
        "# model = keras.models.load_model('model_cross_splited_data.h5')\n",
        "# model.summary()\n",
        "\n",
        "def evaluateModel(prediction, y):\n",
        "    good = 0\n",
        "    for i in range(len(y)):\n",
        "        if (prediction[i] == np.argmax(y[i])):\n",
        "            good = good +1\n",
        "    return (good/len(y)) * 100.0\n",
        "\n",
        "result_test = classifier.predict_classes(X_test)\n",
        "print(\"Correct classification rate on test data\")\n",
        "print(evaluateModel(result_test, y_test))\n",
        "\n",
        "result_train = classifier.predict_classes(X_train)\n",
        "print(\"Correct classification rate on train data\")\n",
        "print(evaluateModel(result_train, y_train))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}